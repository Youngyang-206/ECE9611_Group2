{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e0d06fb",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a08886eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_file = r\"..\\..\\01 Dataset\\03 Data for model\\Train_set.csv\"\n",
    "test_file  = r\"..\\..\\01 Dataset\\03 Data for model\\Test_set.csv\"\n",
    "\n",
    "df_train = pd.read_csv(train_file)\n",
    "df_test  = pd.read_csv(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efb484b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw train shape : (367767, 54)\n",
      "Raw test shape  : (94946, 54)\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw train shape :\", df_train.shape)\n",
    "print(\"Raw test shape  :\", df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f3fcfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "household_ID: 182 unique values\n",
      "--------------------\n",
      "DATE: 366 unique values\n",
      "--------------------\n",
      "TIME: 9968 unique values\n",
      "--------------------\n",
      "own_the_house_or_living_on_rent: 3 unique values\n",
      "['Yes, I or a household member owns it.'\n",
      " 'No, I am living on rent and the rent is paid by me or a household member.'\n",
      " 'No, I or any household member does not own or rent this household. We occupy this household without any payment of rent.']\n",
      "--------------------\n",
      "built_year_of_the_house: 7 unique values\n",
      "['2010-2019' \"Don't know\" '2000-2009' '1990-1999' 'Before 1980'\n",
      " '1980-1989' 'In 2020 or After 2020']\n",
      "--------------------\n",
      "type_of_house: 7 unique values\n",
      "['Single House - Double Floor' 'Single House - Single Floor' 'Twin houses'\n",
      " 'Flat' 'Single House - More than 2 floors' 'Slum / Shanty'\n",
      " 'Line room/row house']\n",
      "--------------------\n",
      "is_there_business_carried_out_in_the_household: 2 unique values\n",
      "['Yes' 'No']\n",
      "--------------------\n",
      "socio_economic_class: 5 unique values\n",
      "['SEC C' 'SEC D' 'SEC B' 'SEC A' 'SEC E']\n",
      "--------------------\n",
      "method_of_receiving_water: 4 unique values\n",
      "['Tap Water (National Water Supply and drainage board)' 'Protected well'\n",
      " 'Tube well'\n",
      " 'Tap Water (Community-based water supply and management organization)']\n",
      "--------------------\n",
      "water_heating_method_for_bathing: 7 unique values\n",
      "[\"We don't have an inbuilt system for water heating, we use water heated by means such as gas, firewood etc. (other than electric kettle, electric water heater or water heated using any other electrical appliance).\"\n",
      " 'None, we do not use hot water for bathing or body wash purposes.'\n",
      " 'We have an in-built water heating system powered solely by the grid supply.'\n",
      " 'We have a water heating system powered by a different source.'\n",
      " 'We have an in-built water heating system powered solely by solar energy.'\n",
      " \"We don't have an inbuilt system for water heating, we use heated water through an electric kettle/heater.\"\n",
      " 'We have an in-built water heating system powered both by solar and the grid supply.']\n",
      "--------------------\n",
      "boil_water_before_drinking: 2 unique values\n",
      "['No' 'Yes']\n",
      "--------------------\n",
      "no_of_times_food_cooked_last_week: 5 unique values\n",
      "['1-7 times' '8 - 14 times' '15 - 21 times'\n",
      " 'Did not cook at home last week' 'More than 21 times']\n",
      "--------------------\n",
      "gas_used_for_cooking: 2 unique values\n",
      "['Yes' 'No']\n",
      "--------------------\n",
      "electricity_from_national_grid_used_for_cooking: 2 unique values\n",
      "['No' 'Yes']\n",
      "--------------------\n",
      "electricity_generated_using_solar_energy_used_for_cooking: 2 unique values\n",
      "['No' 'Yes']\n",
      "--------------------\n",
      "firewood_used_for_cooking: 2 unique values\n",
      "['No' 'Yes']\n",
      "--------------------\n",
      "kerosene_used_for_cooking: 2 unique values\n",
      "['No' 'Yes']\n",
      "--------------------\n",
      "sawdust_or_paddy_husk_used_for_cooking: 1 unique values\n",
      "['No']\n",
      "--------------------\n",
      "biogas_used_for_cooking: 1 unique values\n",
      "['No']\n",
      "--------------------\n",
      "coconut_shells_or_charcoal_used_for_cooking: 2 unique values\n",
      "['No' 'Yes']\n",
      "--------------------\n",
      "timestamp: 90652 unique values\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Check unique values for object columns to determine encoding strategy\n",
    "\n",
    "# Select columns with data type 'object' (commonly used for categorical features)\n",
    "object_cols = df_test.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Iterate over each object-type column\n",
    "for col in object_cols:\n",
    "\n",
    "    # Print the column name and the number of unique values (categories) it has\n",
    "    print(f\"{col}: {df_test[col].nunique()} unique values\")\n",
    "\n",
    "    # If the column has fewer than 20 unique values, print the actual unique categories\n",
    "    if df_test[col].nunique() < 20:\n",
    "        print(df_test[col].unique())\n",
    "\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d77f1cc-542a-41b2-9e9d-fd2fa0703fb7",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6042770e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping useless cols – train: (367767, 48)\n"
     ]
    }
   ],
   "source": [
    "#Drop useless columns\n",
    "useless_cols = ['household_ID', 'DATE', 'TIME', 'timestamp', \n",
    "            'sawdust_or_paddy_husk_used_for_cooking', 'biogas_used_for_cooking']\n",
    "\n",
    "df_train_clean = df_train.drop(columns=useless_cols)\n",
    "df_test_clean  = df_test.drop(columns=useless_cols)\n",
    "\n",
    "print(\"After dropping useless cols – train:\", df_train_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1d24d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cyclical features – train: (367767, 50)\n"
     ]
    }
   ],
   "source": [
    "def create_cyclical_features(df):\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # ----- Encode \"hour\" into cyclical representation -----\n",
    "    # hour_sin = sin(2π * hour / 24)\n",
    "    # hour_cos = cos(2π * hour / 24)\n",
    "    if 'hour' in df_copy.columns:\n",
    "        df_copy['hour_sin'] = np.sin(2 * np.pi * df_copy['hour'] / 24)\n",
    "        df_copy['hour_cos'] = np.cos(2 * np.pi * df_copy['hour'] / 24)\n",
    "\n",
    "        # Remove the original hour column to avoid duplicated information\n",
    "        df_copy = df_copy.drop(columns=['hour'])\n",
    "\n",
    "    # ----- Encode \"month\" into cyclical representation -----\n",
    "    # month_sin = sin(2π * month / 12)\n",
    "    # month_cos = cos(2π * month / 12)\n",
    "    if 'month' in df_copy.columns:\n",
    "        df_copy['month_sin'] = np.sin(2 * np.pi * df_copy['month'] / 12)\n",
    "        df_copy['month_cos'] = np.cos(2 * np.pi * df_copy['month'] / 12)\n",
    "\n",
    "        # Remove the original month column\n",
    "        df_copy = df_copy.drop(columns=['month'])\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "# Apply cyclical encoding to both training and testing sets\n",
    "df_train_clean = create_cyclical_features(df_train_clean)\n",
    "df_test_clean  = create_cyclical_features(df_test_clean)\n",
    "\n",
    "print(\"After cyclical features – train:\", df_train_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e148165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final X_train shape: (367767, 49)\n",
      "Final X_test  shape: (94946, 49)\n",
      "=== y train ===\n",
      "count    367767.000000\n",
      "mean          1.191558\n",
      "std           1.381539\n",
      "min           0.000900\n",
      "25%           0.506000\n",
      "50%           0.847000\n",
      "75%           1.353000\n",
      "max          19.998000\n",
      "Name: future_6h_consumption, dtype: float64\n",
      "=== y test ===\n",
      "count    94946.000000\n",
      "mean         1.055836\n",
      "std          1.128391\n",
      "min          0.000900\n",
      "25%          0.469100\n",
      "50%          0.790000\n",
      "75%          1.255000\n",
      "max         19.993900\n",
      "Name: future_6h_consumption, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Separate features (X) and target variable (y)\n",
    "X_train = df_train_clean.drop(columns='future_6h_consumption')\n",
    "y_train = df_train_clean['future_6h_consumption']\n",
    "\n",
    "X_test = df_test_clean.drop(columns='future_6h_consumption')\n",
    "y_test = df_test_clean['future_6h_consumption']\n",
    "\n",
    "# If there are any missing targets in train, drop those rows\n",
    "mask = y_train.notna()\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "\n",
    "print(\"Final X_train shape:\", X_train.shape)\n",
    "print(\"Final X_test  shape:\", X_test.shape)\n",
    "print(\"=== y train ===\")\n",
    "print(y_train.describe())\n",
    "print(\"=== y test ===\")\n",
    "print(y_test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "187ede93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features: train=34, test=34\n",
      "Categorical features: train=15, test=15\n"
     ]
    }
   ],
   "source": [
    "# Define numeric / categorical feature lists\n",
    "numeric_features_train     = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features_train = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "numeric_features_test     = X_test.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features_test = X_test.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(f\"Numeric features: train={len(numeric_features_train)}, test={len(numeric_features_test)}\")\n",
    "print(f\"Categorical features: train={len(categorical_features_train)}, test={len(categorical_features_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fcb6cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Build preprocessing pipelines\n",
    "# Numeric: Impute missing with Median, Scale\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical: Impute missing with Mode, One-Hot Encode\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine numeric + categorical preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features_train),\n",
    "        ('cat', categorical_transformer, categorical_features_train)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f97e63",
   "metadata": {},
   "source": [
    "# Lasso model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ae3e63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Lasso – Test ===\n",
      "RMSE: 0.8590\n",
      "MAE: 0.4547\n",
      "R2 Score: 0.4204\n"
     ]
    }
   ],
   "source": [
    "# Build and train LassoCV model inside a Pipeline\n",
    "lasso_model = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", LassoCV(cv=5, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate on the test set\n",
    "y_pred = lasso_model.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"=== Lasso – Test ===\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"R2 Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3606c67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha: 0.06436015716520689\n",
      "Selected Features: 14 out of 93\n"
     ]
    }
   ],
   "source": [
    "# Check best alpha\n",
    "best_alpha = lasso_model.named_steps['regressor'].alpha_\n",
    "print(f\"Best Alpha: {best_alpha}\")\n",
    "\n",
    "# Check feature selection (count non-zero coefficients)\n",
    "# Get feature names after one-hot encoding\n",
    "feature_names = (lasso_model.named_steps['preprocessor']\n",
    "                 .transformers_[0][1].get_feature_names_out(numeric_features_train).tolist() + \n",
    "                 lasso_model.named_steps['preprocessor']\n",
    "                 .transformers_[1][1].get_feature_names_out(categorical_features_train).tolist())\n",
    "\n",
    "# Coefficients from Lasso\n",
    "coefs = lasso_model.named_steps['regressor'].coef_\n",
    "selected_features = np.sum(coefs != 0)\n",
    "total_features = len(coefs)\n",
    "\n",
    "print(f\"Selected Features: {selected_features} out of {total_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b1b1182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Features (Lasso):\n",
      "                                    Feature  Coefficient  Abs_Coefficient\n",
      "19                        w1_total_room_acs     0.518353         0.518353\n",
      "0                        TOTAL_IMPORT (kWh)     0.441005         0.441005\n",
      "30                                 hour_sin    -0.119623         0.119623\n",
      "1                        w1_hh_member_count     0.064334         0.064334\n",
      "17                      w1_total_room_bulbs     0.060965         0.060965\n",
      "22  total_monthly_expenditure_of_last_month     0.058813         0.058813\n",
      "31                                 hour_cos    -0.051783         0.051783\n",
      "33                                month_cos    -0.047923         0.047923\n",
      "21                               floor_area     0.031099         0.031099\n",
      "18                       w1_total_room_fans     0.012153         0.012153\n",
      "16                       w1_total_doors_ext     0.009007         0.009007\n",
      "13                     w1_light_hours_night     0.002148         0.002148\n",
      "24                 backward_avg_consumption     0.000335         0.000335\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe of top features\n",
    "feature_importance = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefs})\n",
    "feature_importance['Abs_Coefficient'] = feature_importance['Coefficient'].abs()\n",
    "feature_importance = feature_importance.sort_values(by='Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Features (Lasso):\")\n",
    "print(feature_importance.head(13))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5649cc7b-48fa-4d5d-9ff7-057e519ac046",
   "metadata": {},
   "source": [
    "# Ridge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1b4034a-76c7-484f-aa0e-ae330f1d1d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "# Build Ridge pipeline\n",
    "ridge_model = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),          # same preprocessing\n",
    "    (\"regressor\", RidgeCV(\n",
    "        alphas=np.logspace(-3, 3, 20),      # search alpha from 1e-3 to 1e3\n",
    "        cv=5\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Fit model\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_ridge = ridge_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6045fe7b-47b7-4904-8aa0-a8e6cb9d7353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Ridge – Test ===\n",
      "RMSE : 0.8622\n",
      "MAE  : 0.4778\n",
      "R^2  : 0.4161\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance\n",
    "rmse_ridge = np.sqrt(mean_squared_error(y_test, y_pred_ridge))\n",
    "mae_ridge  = mean_absolute_error(y_test, y_pred_ridge)\n",
    "r2_ridge   = r2_score(y_test, y_pred_ridge)\n",
    "\n",
    "print(\"=== Ridge – Test ===\")\n",
    "print(f\"RMSE : {rmse_ridge:.4f}\")\n",
    "print(f\"MAE  : {mae_ridge:.4f}\")\n",
    "print(f\"R^2  : {r2_ridge:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ba32527-eb6d-4053-acad-021e32928a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Alpha (Ridge): 1000.000000\n"
     ]
    }
   ],
   "source": [
    "# check best alpha\n",
    "best_alpha_ridge = ridge_model.named_steps[\"regressor\"].alpha_\n",
    "print(f\"\\nBest Alpha (Ridge): {best_alpha_ridge:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6638a018-af0f-4a59-ad68-e2fcb31dbcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Features (Ridge):\n",
      "                                              Feature  Coefficient  \\\n",
      "19                                  w1_total_room_acs     0.526045   \n",
      "0                                  TOTAL_IMPORT (kWh)     0.473422   \n",
      "24                           backward_avg_consumption     0.422211   \n",
      "64  method_of_receiving_water_Tap Water (Local Gov...     0.414388   \n",
      "25                             consumption_per_member    -0.379286   \n",
      "48                  type_of_house_Line room/row house     0.333163   \n",
      "50    type_of_house_Single House - More than 2 floors     0.298324   \n",
      "71  water_heating_method_for_bathing_We have a wat...     0.200049   \n",
      "49          type_of_house_Single House - Double Floor    -0.192558   \n",
      "70  water_heating_method_for_bathing_We don't have...    -0.178712   \n",
      "\n",
      "    Abs_Coefficient  \n",
      "19         0.526045  \n",
      "0          0.473422  \n",
      "24         0.422211  \n",
      "64         0.414388  \n",
      "25         0.379286  \n",
      "48         0.333163  \n",
      "50         0.298324  \n",
      "71         0.200049  \n",
      "49         0.192558  \n",
      "70         0.178712  \n"
     ]
    }
   ],
   "source": [
    "# 6. Ridge coefficients + feature names\n",
    "num_feature_names_r = (\n",
    "    ridge_model.named_steps[\"preprocessor\"]\n",
    "    .transformers_[0][1]\n",
    "    .get_feature_names_out(numeric_features_train)\n",
    ")\n",
    "cat_feature_names_r = (\n",
    "    ridge_model.named_steps[\"preprocessor\"]\n",
    "    .transformers_[1][1]\n",
    "    .get_feature_names_out(categorical_features_train)\n",
    ")\n",
    "feature_names_ridge = np.concatenate([num_feature_names_r, cat_feature_names_r])\n",
    "\n",
    "coefs_ridge = ridge_model.named_steps[\"regressor\"].coef_\n",
    "\n",
    "# Make a dataframe of feature importance\n",
    "feature_importance_ridge = pd.DataFrame({\n",
    "    \"Feature\": feature_names_ridge,\n",
    "    \"Coefficient\": coefs_ridge\n",
    "})\n",
    "feature_importance_ridge[\"Abs_Coefficient\"] = feature_importance_ridge[\"Coefficient\"].abs()\n",
    "feature_importance_ridge = feature_importance_ridge.sort_values(\n",
    "    by=\"Abs_Coefficient\", ascending=False\n",
    ")\n",
    "\n",
    "print(\"\\nTop 10 Features (Ridge):\")\n",
    "print(feature_importance_ridge.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72156494-9313-48c7-b7d6-7e986f101d64",
   "metadata": {},
   "source": [
    "# Elastic Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d12cfdf-ca99-4fcc-80a5-babbaeea48fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "# Build Elastic Net pipeline\n",
    "# ElasticNetCV will search for the best alpha and l1_ratio\n",
    "elastic_model = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", ElasticNetCV(\n",
    "        l1_ratio=[0.1, 0.3, 0.5, 0.7, 0.9],  # mix of L1 and L2\n",
    "        cv=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Fit model\n",
    "elastic_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_elastic = elastic_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0686e7db-7d1b-445e-a57d-a6b2354a608d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Elastic Net – Test ===\n",
      "RMSE : 0.8589\n",
      "MAE  : 0.4545\n",
      "R^2  : 0.4206\n",
      "\n",
      "Best Alpha   (Elastic Net): 0.071511\n",
      "Best l1_ratio(Elastic Net): 0.900\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance\n",
    "rmse_elastic = np.sqrt(mean_squared_error(y_test, y_pred_elastic))\n",
    "mae_elastic  = mean_absolute_error(y_test, y_pred_elastic)\n",
    "r2_elastic   = r2_score(y_test, y_pred_elastic)\n",
    "\n",
    "print(\"=== Elastic Net – Test ===\")\n",
    "print(f\"RMSE : {rmse_elastic:.4f}\")\n",
    "print(f\"MAE  : {mae_elastic:.4f}\")\n",
    "print(f\"R^2  : {r2_elastic:.4f}\")\n",
    "\n",
    "# Check best alpha and l1_ratio chosen by ElasticNetCV\n",
    "best_alpha_en   = elastic_model.named_steps[\"regressor\"].alpha_\n",
    "best_l1_ratio   = elastic_model.named_steps[\"regressor\"].l1_ratio_\n",
    "print(f\"\\nBest Alpha   (Elastic Net): {best_alpha_en:.6f}\")\n",
    "print(f\"Best l1_ratio(Elastic Net): {best_l1_ratio:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f027019-82a1-4486-b0c1-f72c9acaee53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Features (Elastic Net):\n",
      "                                    Feature  Coefficient  Abs_Coefficient\n",
      "19                        w1_total_room_acs     0.514123         0.514123\n",
      "0                        TOTAL_IMPORT (kWh)     0.438869         0.438869\n",
      "30                                 hour_sin    -0.116603         0.116603\n",
      "1                        w1_hh_member_count     0.063851         0.063851\n",
      "17                      w1_total_room_bulbs     0.061615         0.061615\n",
      "22  total_monthly_expenditure_of_last_month     0.058750         0.058750\n",
      "31                                 hour_cos    -0.054246         0.054246\n",
      "33                                month_cos    -0.047566         0.047566\n",
      "21                               floor_area     0.032044         0.032044\n",
      "18                       w1_total_room_fans     0.011869         0.011869\n"
     ]
    }
   ],
   "source": [
    "# Inspect feature importance\n",
    "num_feature_names_en = (\n",
    "    elastic_model.named_steps[\"preprocessor\"]\n",
    "    .transformers_[0][1]\n",
    "    .get_feature_names_out(numeric_features_train)\n",
    ")\n",
    "\n",
    "cat_feature_names_en = (\n",
    "    elastic_model.named_steps[\"preprocessor\"]\n",
    "    .transformers_[1][1]\n",
    "    .get_feature_names_out(categorical_features_train)\n",
    ")\n",
    "\n",
    "feature_names_en = np.concatenate([num_feature_names_en, cat_feature_names_en])\n",
    "\n",
    "coefs_en = elastic_model.named_steps[\"regressor\"].coef_\n",
    "\n",
    "feature_importance_en = pd.DataFrame({\n",
    "    \"Feature\": feature_names_en,\n",
    "    \"Coefficient\": coefs_en\n",
    "})\n",
    "feature_importance_en[\"Abs_Coefficient\"] = feature_importance_en[\"Coefficient\"].abs()\n",
    "feature_importance_en = feature_importance_en.sort_values(\n",
    "    by=\"Abs_Coefficient\", ascending=False\n",
    ")\n",
    "\n",
    "print(\"\\nTop 10 Features (Elastic Net):\")\n",
    "print(feature_importance_en.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e5116a3-ad5a-42ef-8be5-237e917e74fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "#Output the L1 ratio\n",
    "print(elastic_model.named_steps['regressor'].l1_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca46930c-f805-47a9-bbd1-68bb5237e582",
   "metadata": {},
   "source": [
    "# Save the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7532eaa9-c8c5-4ee9-bfe6-21fa8291604a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: elastic  (R² = 0.4206)\n",
      "   y_test    y_pred  abs_error\n",
      "0   0.810  0.771859   0.038141\n",
      "1   0.616  1.069715   0.453715\n",
      "2   0.558  0.719925   0.161925\n",
      "3   0.583  0.679817   0.096817\n",
      "4   1.085  0.962730   0.122270\n"
     ]
    }
   ],
   "source": [
    "# Select Best Model \n",
    "results = {\n",
    "    \"lasso\":   r2,\n",
    "    \"ridge\":   r2_ridge,\n",
    "    \"elastic\": r2_elastic\n",
    "}\n",
    "\n",
    "best_model_name = max(results, key=results.get)\n",
    "print(f\"Best Model: {best_model_name}  (R² = {results[best_model_name]:.4f})\")\n",
    "\n",
    "# Map name → model reference\n",
    "model_dict = {\n",
    "    \"lasso\": lasso_model,\n",
    "    \"ridge\": ridge_model,\n",
    "    \"elastic\": elastic_model\n",
    "}\n",
    "\n",
    "best_model = model_dict[best_model_name]\n",
    "\n",
    "# Predict Again with the Best Model\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Create DataFrame\n",
    "df_result = pd.DataFrame({\n",
    "    \"y_test\": y_test.values,\n",
    "    \"y_pred\": y_pred_best,\n",
    "    \"abs_error\": np.abs(y_test.values - y_pred_best)\n",
    "})\n",
    "\n",
    "print(df_result.head())\n",
    "\n",
    "# Save to CSV\n",
    "output_name = f\"best_model_predictions_{best_model_name}.csv\"\n",
    "df_result.to_csv(output_name, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73557722-86d6-461d-8abd-25dc598a99b0",
   "metadata": {},
   "source": [
    "# Draw Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b95d90-9a2c-405b-a7cd-98823db02de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ---------- Residuals ----------\n",
    "residuals = y_test.values - y_pred_best\n",
    "\n",
    "# ---------- Predicted vs True ----------\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.scatterplot(x=y_test, y=y_pred_best, alpha=0.3)\n",
    "sns.regplot(x=y_test, y=y_pred_best, scatter=False, lowess=True, color='red')\n",
    "plt.plot([y_test.min(), y_test.max()],\n",
    "         [y_test.min(), y_test.max()],\n",
    "         'g--', label='Ideal Line')\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(f\"Predicted vs True ({best_model_name} Model)\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# ---------- Residual Plot ----------\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.scatterplot(x=y_pred_best, y=residuals, alpha=0.3)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals (y_test - y_pred)\")\n",
    "plt.title(f\"Residual Plot ({best_model_name} Model)\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# ----------  Top 15 Coefficients with names ----------\n",
    "preprocessor = best_model.named_steps['preprocessor']\n",
    "regressor = best_model.named_steps['regressor']\n",
    "\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "coefs = regressor.coef_\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Coefficient\": coefs\n",
    "})\n",
    "coef_df[\"Abs\"] = coef_df[\"Coefficient\"].abs()\n",
    "coef_df = coef_df.sort_values(\"Abs\", ascending=False).head(15)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(data=coef_df, x=\"Abs\", y=\"Feature\")\n",
    "plt.xlabel(\"Absolute Coefficient\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(f\"Top 15 Coefficients ({best_model_name} Model)\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40485dd-ead7-4aa0-97fe-202f4290b419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
